{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvWl3ebqzCc1"
   },
   "source": [
    "# Instructions\n",
    "- Some parts of the code are already done for you\n",
    "- You need to execute all the cells\n",
    "- You need to add the code where ever you see `\"#### Add your code here ####\"`\n",
    "- Marks are mentioned along with the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgR0j5310qqC"
   },
   "source": [
    "# Face detection\n",
    "Task is to predict the boundaries(mask) around the face in a given image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aa0jyJzw091I"
   },
   "source": [
    "## Dataset\n",
    "Faces in images marked with bounding boxes. Have around 500 images with around 1100 faces manually tagged via bounding box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjRTlPkp1LC2"
   },
   "source": [
    "### Mount Google drive if you are using google colab\n",
    "- We recommend using Google Colab as you can face memory issues and longer runtimes while running on local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "sBWMoTJ9cf3Z",
    "outputId": "458ba787-36e6-47cb-bd6a-02e4c56ac7fe"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sO9mgMmp13sI"
   },
   "source": [
    "### Change current working directory to project folder (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TddMnf4D1-59"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Face Detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2b7e67113518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#os.chdir('/home/balachandra/Desktop/Data Science/GreatLearning/Projects/Project 9 - Face Detection')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/Face Detection'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Face Detection'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/home/balachandra/Desktop/Data Science/GreatLearning/Projects/Project 9 - Face Detection')\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/Face Detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3srplE-FEpKa"
   },
   "source": [
    "### Load the \"images.npy\" file (4 marks)\n",
    "- This file contains images with details of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqFE_tZDf0sM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('/content/drive/My Drive/Projects/Neural Networks/images.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "YTW3K-KBmuXT",
    "outputId": "f3ccbcbd-760e-44eb-b5aa-f871f53fc6cd"
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SMP8zliFT7R"
   },
   "source": [
    "### Check one sample from the loaded \"images.npy\" file  (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tWEkhtbFmuXj",
    "outputId": "9b88804d-09fe-45e4-e739-6a1cca3a0d34"
   },
   "outputs": [],
   "source": [
    "data[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m94G4p3CE5Cj"
   },
   "source": [
    "### Set image dimensions   (2 marks)\n",
    "- Initialize image height, image width with value: 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFqmpq1YmuX2"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kuZmtOASevDo"
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = img_rows\n",
    "IMAGE_HEIGHT = img_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wY6FEsCjG47s"
   },
   "source": [
    "### Create features and labels\n",
    "- Here feature is the image\n",
    "- The label is the mask\n",
    "- Images will be stored in \"X_train\" array\n",
    "- Masks will be stored in \"masks\" array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "XjCT9EVTgAvr",
    "outputId": "950dc70c-de49-43ff-a693-4348eba9df3b"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "masks = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "X_train = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "for index in range(data.shape[0]):\n",
    "    img = data[index][0]\n",
    "    img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "    try:\n",
    "      img = img[:, :, :3]\n",
    "    except:\n",
    "      continue\n",
    "    X_train[index] = preprocess_input(np.array(img, dtype=np.float32))\n",
    "    for i in data[index][1]:\n",
    "        x1 = int(i[\"points\"][0]['x'] * IMAGE_WIDTH)\n",
    "        x2 = int(i[\"points\"][1]['x'] * IMAGE_WIDTH)\n",
    "        y1 = int(i[\"points\"][0]['y'] * IMAGE_HEIGHT)\n",
    "        y2 = int(i[\"points\"][1]['y'] * IMAGE_HEIGHT)\n",
    "        masks[index][y1:y2, x1:x2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3AYbP79bFtJ"
   },
   "source": [
    "### Print the shape of X_train and mask array  (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3PIRaEdWIjDa",
    "outputId": "52ba6309-26f3-4c6c-e636-fdcb182d70cf"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4wgkWq1bk5F"
   },
   "source": [
    "### Print a sample image and image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qfRZjQufj0N9",
    "outputId": "b915d137-5178-463f-96b2-4d37fe9e8158"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "n = 10\n",
    "print(X_train[n])\n",
    "pyplot.imshow(X_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "983gGKcwlSe8",
    "outputId": "6179b3b3-bc5f-4297-a20d-980bb43f8576"
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(masks[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0Qa1UOue9TE"
   },
   "source": [
    "## Create the model (10 marks)\n",
    "- Add MobileNet as model with below parameter values\n",
    "  - input_shape: IMAGE_HEIGHT, IMAGE_WIDTH, 3\n",
    "  - include_top: False\n",
    "  - alpha: 1.0\n",
    "  - weights: \"imagenet\"\n",
    "- Add UNET architecture layers\n",
    "  - This is the trickiest part of the project, you need to research and implement it correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTVYOvANrUVx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Concatenate, UpSampling2D, Conv2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_model(trainable=True):\n",
    "    model = MobileNet(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), include_top=False, \n",
    "                      alpha=1.0, weights=\"imagenet\")\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "    \n",
    "    block0 = model.get_layer(\"conv_pw_1_relu\").output\n",
    "    block1 = model.get_layer(\"conv_pw_1_relu\").output\n",
    "    block2 = model.get_layer(\"conv_pw_3_relu\").output\n",
    "    block3 = model.get_layer(\"conv_pw_5_relu\").output\n",
    "    block4 = model.get_layer(\"conv_pw_11_relu\").output\n",
    "    block5 = model.get_layer(\"conv_pw_13_relu\").output\n",
    "\n",
    "    x = Concatenate()([UpSampling2D()(block5), block4])\n",
    "    print(x.shape)\n",
    "    x = Concatenate()([UpSampling2D()(x), block3])\n",
    "    print(x.shape)\n",
    "    x = Concatenate()([UpSampling2D()(x), block2])\n",
    "    print(x.shape)\n",
    "    x = Concatenate()([UpSampling2D()(x), block1])\n",
    "    print(x.shape)\n",
    "    x = UpSampling2D()(x)\n",
    "            \n",
    "    x = Conv2D(1, kernel_size=1, activation=\"sigmoid\")(x)\n",
    "    x = Reshape((224, 224))(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_snZ9o0ZBAiv"
   },
   "source": [
    "### Call the create_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9TfSSP51uPoO",
    "outputId": "493dd4a9-b248-41f2-df09-db6afd55b492"
   },
   "outputs": [],
   "source": [
    "# Give trainable=False as argument, if you want to freeze lower layers for fast training (but low accuracy)\n",
    "model = create_model()\n",
    "\n",
    "# Print summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bcATnQzomuZc",
    "outputId": "c22b6fb5-5bba-42eb-d707-f134b0b5590b"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2spcE4TvfEZw"
   },
   "source": [
    "### Define dice coefficient function (5 marks)\n",
    "- Create a function to calculate dice coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8H8aViXZuWz1"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    numerator = 2 * tensorflow.reduce_sum(y_true * y_pred)\n",
    "    denominator = tensorflow.reduce_sum(y_true + y_pred)\n",
    "    \n",
    "    return numerator / (denominator + tensorflow.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nkp5SDM1fIu2"
   },
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEOVfs19KVLv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.backend import log, epsilon\n",
    "def loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Thltv_akfOMS"
   },
   "source": [
    "### Compile the model (5 marks)\n",
    "- Complie the model using below parameters\n",
    "  - loss: use the loss function defined above\n",
    "  - optimizers: use Adam optimizer\n",
    "  - metrics: use dice_coefficient function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnxNEO9UmuZ-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[dice_coefficient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atPb8xm2qkK5"
   },
   "outputs": [],
   "source": [
    "#### Add your code here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VTumZyg0fuVy"
   },
   "source": [
    "### Define checkpoint and earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QNlQHt8DMy7h",
    "outputId": "9172adf1-6043-4f95-962a-4712e650b706"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"min\", period=1)\n",
    "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxxbwvXEf07e"
   },
   "source": [
    "### Fit the model (5 marks)\n",
    "- Fit the model using below parameters\n",
    "  - epochs: you can decide\n",
    "  - batch_size: 1\n",
    "  - callbacks: checkpoint, reduce_lr, stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mYn84FF2muaW",
    "outputId": "a04010bb-f873-4574-e712-29489323a2c0"
   },
   "outputs": [],
   "source": [
    "model.fit(x = X_train, y = masks, batch_size = 1, epochs = 100, \n",
    "          callbacks = [checkpoint, reduce_lr, stop], verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VtnuzlOf4uL"
   },
   "source": [
    "### Get the predicted mask for a sample image   (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-CBCMysrchu"
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "region = model.predict(np.array([X_train[n]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDIetz0HgA4R"
   },
   "source": [
    "### Impose the mask on the image (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "6gRwfOqNmua4",
    "outputId": "9a727b45-73cc-415c-cf4d-243e1c16fe4f"
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(X_train[n], 'gray', interpolation = None)\n",
    "pyplot.imshow(masks[n], 'Greens', interpolation = None, alpha = 0.7)\n",
    "pyplot.imshow(region[0], 'jet', interpolation = None, alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "NuwkA2id7jA7",
    "outputId": "923b2930-2aa8-4196-96d5-7fba2bc0bfb3"
   },
   "outputs": [],
   "source": [
    "n = 16\n",
    "region = model.predict(np.array([X_train[n]]))\n",
    "pyplot.imshow(X_train[n], 'gray', interpolation = None)\n",
    "pyplot.imshow(masks[n], 'Greens', interpolation = None, alpha = 0.7)\n",
    "pyplot.imshow(region[0], 'jet', interpolation = None, alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "Q4KoDzuEr_1q",
    "outputId": "4d974057-5421-4033-a409-1a67d9af173a"
   },
   "outputs": [],
   "source": [
    "n = 36\n",
    "region = model.predict(np.array([X_train[n]]))\n",
    "pyplot.imshow(X_train[n])\n",
    "pyplot.imshow(masks[n], 'Greens', interpolation = None, alpha = 0.7)\n",
    "pyplot.imshow(region[0], 'jet', alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "njq19pCyvQ0k",
    "outputId": "16be3495-8be6-44fc-8e96-71c5b5a5c1d4"
   },
   "outputs": [],
   "source": [
    "n = 360\n",
    "region = model.predict(np.array([X_train[n]]))\n",
    "pyplot.imshow(X_train[n])\n",
    "pyplot.imshow(masks[n], 'Greens', interpolation = None, alpha = 0.7)\n",
    "pyplot.imshow(region[0], 'jet', alpha = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEK_St16vsYn"
   },
   "source": [
    "Model built is able to predict the faces accurately. In above plots, blue boxes represents ground truth and yellow ones overlapping the blue boxes represent predictions. In all the samples above, it can detect the faces accurately.\n",
    "\n",
    "Same can be observed in the dice coefficeint which is around 90.67%. We can say the model is able to generalize well."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Face_detection_Questions_Project_CV_AIML_Online.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
